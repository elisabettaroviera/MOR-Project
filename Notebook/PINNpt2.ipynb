{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "481ac8ab-a6e7-424f-8610-1d7c0c1689ef",
   "metadata": {},
   "source": [
    "# Model Order Reduction & Machine Learning - Project\n",
    "## Nonlinear Elliptic problem (NEP) **PINN**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8805e70c-ee75-4fe1-a2d3-27ebf8a1341b",
   "metadata": {},
   "source": [
    "### Importing library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42354ebf-3495-42e3-b0ef-c4d2d3a49187",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fafcdc-48ef-4e58-be74-8736e673a26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../CppToPython')\n",
    "\n",
    "import numpy as np\n",
    "import GeDiM4Py as gedim\n",
    "from scipy.sparse.linalg import splu\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Run to avoid to many warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b765763-fee4-4dcc-b232-5b2cc68c724d",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55794bed-b5fc-4621-a424-af31a75b6e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib = gedim.ImportLibrary(\"../../CppToPython/release/GeDiM4Py.so\")\n",
    "\n",
    "config = { 'GeometricTolerance': 1.0e-8 }\n",
    "gedim.Initialize(config, lib)\n",
    "\n",
    "np.random.seed(23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a837a16b-6061-4b9c-b05f-bf68b0e6c8a3",
   "metadata": {},
   "source": [
    "## PART 2\n",
    "Let us consider the two-dimensional spatial domain $\\Omega = (0, 1)^2$. We want to solve the following parametrized problem: given $\\mu = (\\mu_0, \\mu_1) \\in \\mathcal{P} = [0.1, 1]^2$, find $u(\\mu)$ such that\n",
    "$$\n",
    "-\\Delta u(\\mu) + \\frac{\\mu_0}{\\mu_1} (e^{\\mu_1 u(\\mu)} - 1) = g(x;\\mu),\n",
    "$$\n",
    "with homogeneous Dirichlet condition on the boundary, i.e. zero-boundary condition.\n",
    "\n",
    "The forcing term, that does not depend on the parameters, defined as\n",
    "$$\n",
    "g(x;\\mu) = g_1 = 100 \\sin(2\\pi x_0) \\cos(2\\pi x_1) \\quad \\forall x = (x_0, x_1) \\in \\Omega.\n",
    "$$\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "1. Solve the problem by means of POD-Galerkin method over a Finite Element full order model -> using high fidelity element approximation of POD\n",
    "2. Solve the problem with a parametric PINN -> find the NN structure to reduce the problem\n",
    "3. Compare the two approaches in terms of computational costs and accuracy with respect to the full order model -> compare in terms of execution time & error\n",
    "4. **Optional:** Solve the problem with the POD-NN approach and compare it to the other two strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8baa142-970c-4f51-ba62-ae272845cec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Points for the diffusion term\n",
    "def Elliptic_a(numPoints, points): \n",
    "\tvalues_a = np.ones(numPoints, order='F') # Fortran order of memorization of the matrix: column by column\n",
    "\treturn values_a.ctypes.data\n",
    "\n",
    "# Points for the reaction term\n",
    "def Elliptic_c(numPoints, points):\n",
    "\tvalues_c = np.ones(numPoints, order='F') \n",
    "\treturn values_c.ctypes.data    \n",
    "\n",
    "# Non linear reaction term\n",
    "# numPoints := quadrature points\n",
    "def Elliptic_non_linear_c(numPoints, points, u, u_x, u_y):\n",
    "\tvec_u = gedim.make_nd_array(u, numPoints, np.double) # Evaluation of the function in the quadrature points numPoints\n",
    "\tvalues_nl_c = vec_u\n",
    "\treturn values_nl_c.ctypes.data\n",
    "\n",
    "def Elliptic_non_linear_der_f(numPoints, points, u, u_x, u_y):\n",
    "    # Converts u_x and u_y pointers or arrays to NumPy arrays\n",
    "\tvecu_x = gedim.make_nd_array(u_x, numPoints, np.double)\n",
    "\tvecu_y = gedim.make_nd_array(u_y, numPoints, np.double)\n",
    "    \n",
    "\tvalues_nl_d_f = np.zeros((2, numPoints), order='F')\n",
    "\n",
    "    # Inserts the partial derivatives of u into the new array values_nl_d_f\n",
    "\tvalues_nl_d_f[0,:] = vecu_x\n",
    "\tvalues_nl_d_f[1,:] = vecu_y\n",
    "    \n",
    "\treturn values_nl_d_f.ctypes.data\n",
    "\n",
    "# Nonlinear reaction term\n",
    "def Elliptic_non_linear_f(numPoints, points, u, u_x, u_y): \n",
    "    vec_u = gedim.make_nd_array(u, numPoints, np.double)\n",
    "    vecu_x = gedim.make_nd_array(u_x, numPoints, np.double)\n",
    "    vecu_y = gedim.make_nd_array(u_y, numPoints, np.double)\n",
    "    \n",
    "    values_nl_f = (mu_0/mu_1) * (np.exp(mu_1*vec_u)-1) # Computation of f\n",
    "    \n",
    "    return values_nl_f.ctypes.data\n",
    "\n",
    "def Elliptic_exactSolution(numPoints, points):\n",
    "\tmatPoints = gedim.make_nd_matrix(points, (3, numPoints), np.double)\n",
    "\n",
    "    # Definition of u\n",
    "\tvalues_ex = mu_0 * (matPoints[1,:] * (1.0 - matPoints[1,:]) * matPoints[0,:] * (1.0 - matPoints[0,:]))\n",
    "    \n",
    "\treturn values_ex.ctypes.data\n",
    "\n",
    "def Elliptic_exactDerivativeSolution(direction, numPoints, points):\n",
    "\tmatPoints = gedim.make_nd_matrix(points, (3, numPoints), np.double)\n",
    "\n",
    "\tif direction == 0: # wrt x\n",
    "\t\tvalues_ex_d = mu_0 * (1.0 - 2.0 * matPoints[0,:]) * matPoints[1,:] * (1.0 - matPoints[1,:]) # 16⋅(1−2x)⋅y⋅(1−y)\n",
    "\telif direction == 1: # wrt y\n",
    "\t\tvalues_ex_d = mu_0 * (1.0 - 2.0 * matPoints[1,:]) * matPoints[0,:] * (1.0 - matPoints[0,:]) # 16⋅(1−2y)⋅x⋅(1−x)\n",
    "\telse:\n",
    "\t\tvalues_ex_d = np.zeros(numPoints, order='F')\n",
    "\n",
    "\treturn values_ex_d.ctypes.data\n",
    "\n",
    "# Forcing term for evaluating the error\n",
    "def Elliptic_exactSolution_g(numPoints, points):\n",
    "    matPoints = gedim.make_nd_matrix(points, (3, numPoints), np.double)\n",
    "    \n",
    "    # Definition of u\n",
    "    # values_ex = 2*mu_0*(y*(1-y)+x*(1-x)) + (mu_0/mu_1)*(np.exp(mu_0*mu_1*x*y*(1-x)(1-y)) -1)\n",
    "    values_ex = 2*mu_0*(matPoints[1,:]*(1-matPoints[1,:])+matPoints[0,:]*(1-matPoints[0,:])) + (mu_0/mu_1)*(np.exp(mu_0*mu_1*matPoints[0,:]*matPoints[1,:]*(1-matPoints[0,:])*(1-matPoints[1,:])) -1)\n",
    "    \n",
    "    return values_ex.ctypes.data\n",
    "\n",
    "def Ones(numPoints, points):\n",
    "\tvalues_one = np.ones(numPoints, order='F')\n",
    "\treturn values_one.ctypes.data\n",
    "\n",
    "def OnesDerivative(numPoints, points):\n",
    "\tvalues_one_d = np.ones((2, numPoints), order='F')\n",
    "\treturn values_one_d.ctypes.data\n",
    "\n",
    "def Zeros(numPoints, points):\n",
    "\tvalues_zero = np.zeros(numPoints, order='F')\n",
    "\treturn values_zero.ctypes.data\n",
    "\n",
    "def ZerosDerivative(direction, numPoints, points):\n",
    "\tvalues_zero_d = np.zeros(numPoints, order='F')\n",
    "\treturn values_zero_d.ctypes.data\n",
    "\n",
    "# Definition of the forcing term g_1\n",
    "def Elliptic_g_1(numPoints, points): \n",
    "    matPoints = gedim.make_nd_matrix(points, (3, numPoints), np.double) # X\n",
    "    # g_1(X,mu) = 100*sin(2*mu_0*pi*x)*cos(2*mu_0*pi*y), X=(x,y)\n",
    "    values_g = 100*np.sin(2*mu_0*np.pi*matPoints[0,:])*np.cos(2*mu_0*np.pi*matPoints[1,:])\n",
    "    return values_g.ctypes.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82ed432-98cd-464d-964d-54e9dc0c643f",
   "metadata": {},
   "source": [
    "#### Mesh and domain definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ae53ba-23d3-47a9-a1a8-23d54cb62eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = 1 # Start from 1, at the END we will decide if we have to improve the order\n",
    "P = [0.1, 1.] # Parametric space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8693fae1-2395-4db9-9028-3a3f1286d4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the right domain\n",
    "mesh_size = 0.00312\n",
    "\n",
    "# Updating the domain wrt the mesh_size\n",
    "domain = { 'SquareEdge': 1.0, 'VerticesBoundaryCondition': [1,1,1,1], 'EdgesBoundaryCondition': [1,1,1,1], 'DiscretizationType': 1, 'MeshCellsMaximumArea': mesh_size } \n",
    "[meshInfo, mesh] = gedim.CreateDomainSquare(domain, lib) \n",
    "discreteSpace = { 'Order': order, 'Type': 1, 'BoundaryConditionsType': [1, 2] } # 2 := Dirichlet boundary condition\n",
    "[problemData, dofs, strongs] = gedim.Discretize(discreteSpace, lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aee8275-bb2e-41d6-ac51-089b3375abf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization of the guess of the solution --> the NM converges rapidly if we start not far away from the solution\n",
    "u_k = np.zeros(problemData['NumberDOFs'], order='F') \n",
    "u_strong = np.zeros(problemData['NumberStrongs'], order='F') # Vector containing the strongly imposed components of the solution, ie Dirichlet conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d67f32a-1e2d-453b-ac8b-7fc5938a4b15",
   "metadata": {},
   "source": [
    "#### Newton method for high fidelity snapshots computation - TO COMPUTE THE ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79ec54d-172d-41a8-9bbb-120233ede68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_mu_0 = np.random.uniform(0.1, 1, 300) # Uniform sampling in mu_Rang of 100 samples\n",
    "sample_mu_1 = np.random.uniform(0.1, 1, 300)\n",
    "\n",
    "snapshots_matrix = []\n",
    "convergence_history = []  \n",
    "max_iterations = 100\n",
    "newton_tol = 1e-8\n",
    "sol_quad_hf = []\n",
    "\n",
    "for mu_0, mu_1 in zip(sample_mu_0, sample_mu_1):\n",
    "    \n",
    "    # Set Newton parameter at each change of the parameter\n",
    "    du_norm = 1.0\n",
    "    u_k_norm = 1.0\n",
    "    num_iteration = 1\n",
    "    du_norms_for_sample = []\n",
    "    num_iteration = 1\n",
    "    rel_error = 0\n",
    "\n",
    "    # Iterative step - Setting a relative tollerance\n",
    "    while num_iteration < max_iterations and du_norm > newton_tol * u_k_norm: \n",
    "\n",
    "        # 1- Left side of the equation\n",
    "        \n",
    "        # Linear\n",
    "        [stiffness, stiffnessStrong] = gedim.AssembleStiffnessMatrix(Elliptic_a, problemData, lib) # Indipendent from mu_0 & mu_1\n",
    "        # Non linear \n",
    "        [reaction, reactionStrong] = gedim.AssembleNonLinearReactionMatrix(Elliptic_c, Elliptic_non_linear_c, u_k, u_strong, problemData, lib)\n",
    "       \n",
    "        # 2- Right hand side of the function\n",
    "        \n",
    "        # Linear part\n",
    "        forcingTerm_g = gedim.AssembleForcingTerm(Elliptic_g_1, problemData, lib)\n",
    "        # Non linear part\n",
    "        forcingTerm_v = gedim.AssembleNonLinearForcingTerm(Ones, Elliptic_non_linear_f, u_k, u_strong, problemData, lib)\n",
    "        forcingTerm_der_v = gedim.AssembleNonLinearDerivativeForcingTerm(OnesDerivative, Elliptic_non_linear_der_f, u_k, u_strong, problemData, lib)\n",
    "    \n",
    "        # Solving with the LU solver because we're in a generic setting (no idea of the structure of the matrix)\n",
    "        # CAN WE DONE BETTER?\n",
    "        du = gedim.LUSolver(stiffness + reaction, \\\n",
    "                forcingTerm_g - forcingTerm_v - forcingTerm_der_v, \\\n",
    "                lib)\n",
    "        \n",
    "        u_k = u_k + du # Update\n",
    "        \n",
    "        # Compute norm for stopping criterium\n",
    "        du_norm = gedim.ComputeErrorL2(Zeros, du, np.zeros(problemData['NumberStrongs'], order='F'), lib)  # ||du|| = ||u(k) - u(k-1)|| L^2-norm\n",
    "        du_norms_for_sample.append(du_norm)\n",
    "        u_k_norm = gedim.ComputeErrorL2(Zeros, u_k, u_strong, lib) # ||u_k|| L^2-norm\n",
    "\n",
    "    \n",
    "        # Compute the relative error of two consecutive iterations\n",
    "        rel_error = du_norm / u_k_norm       \n",
    "        \n",
    "        num_iteration = num_iteration + 1\n",
    "\n",
    "    snapshots_matrix.append(np.copy(u_k))\n",
    "    convergence_history.append(du_norms_for_sample)\n",
    "\n",
    "    # Compute the sol on the quadrature points\n",
    "    [numQuadraturePoints, quadraturePoints, quadratureWeights, solution_hf, solution_x_hf, solution_y_hf] = gedim.EvaluateSolutionOnPoints(u_k, u_strong, lib)\n",
    "    # append solution on qudrature points\n",
    "    sol_quad_hf.append(solution_hf)\n",
    "\n",
    "    # Print at the end of the iteration before the change of the parameter\n",
    "    #print(f\"{'mu_0':<10} {'mu_1':<10} {'iters':<6} {'rel_err_L2':<14}\")\n",
    "    #print(f\"{mu_0:<10.4f} {mu_1:<10.4f} {(num_iteration-1):<6d} {rel_error:<14.2e}\")\n",
    "\n",
    "snapshots_matrix = np.array(snapshots_matrix)\n",
    "print(f\"snapshots_matrix.shape: {snapshots_matrix.shape}\")\n",
    "\n",
    "# Just to check the final u_k, mu_0, mu_1\n",
    "last_u_k_exact = u_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1a3dff-9949-4869-8e29-04e92daa090e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and show the solution\n",
    "gedim.PlotSolution(mesh, dofs, strongs, last_u_k_exact, u_strong)\n",
    "[numQuadraturePoints, quadraturePoints, quadratureWeights, sol, sol_x, sol_y] = gedim.EvaluateSolutionOnPoints(last_u_k_exact, u_strong, lib)\n",
    "gedim.ExportSolutionOnPoints(numQuadraturePoints, quadraturePoints, last_u_k_exact, lib)\n",
    "print(f\"quadratureWeights: {quadratureWeights}\")\n",
    "\n",
    "gedim.ExportSolutionOnPoints(numQuadraturePoints, quadraturePoints, sol, lib) # To export solutions on paraview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c843e5ed-6a98-40a3-ab21-b8cc95686b01",
   "metadata": {},
   "source": [
    "## 2. PINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec81679-9a81-4bea-8190-80805ff5241c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for the first epoch\n",
    "def generate_data(N_domain=1750, N_boundary=150):\n",
    "    # Points in the domain\n",
    "    x_in = torch.rand((N_domain, 2))  # [x0, x1] ∈ Ω\n",
    "    mu_in = (torch.rand((1, 2)) * 0.9 + 0.1).expand(N_domain, -1) # [mu0, mu1] ∈ [0.1, 1]^2\n",
    "\n",
    "    # Points on the border of the domain (edge of the square)\n",
    "    x0 = torch.rand(N_boundary, 1)\n",
    "    zeros = torch.zeros_like(x0)\n",
    "    ones = torch.ones_like(x0)\n",
    "\n",
    "    xb = torch.cat([\n",
    "        torch.cat([x0, zeros], dim=1),\n",
    "        torch.cat([x0, ones], dim=1),\n",
    "        torch.cat([zeros, x0], dim=1),\n",
    "        torch.cat([ones, x0], dim=1)\n",
    "    ], dim=0)\n",
    "\n",
    "    mu_b = mu_in[:N_boundary*4, :]\n",
    "    return x_in, mu_in, xb, mu_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15036b87-1ff2-4177-a506-5e12fc1f28fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all the other epochs, it samples on the point on the domain in which the loss is higher so that he can learn better\n",
    "def adaptive_sample(model, N_tot=5000, N_sel=1750, N_boundary=150):\n",
    "    X = torch.rand(N_tot, 2, device=device)\n",
    "    M = (torch.rand(N_tot, 2, device=device) * 0.9 + 0.1)\n",
    "\n",
    "    # Compute the residual\n",
    "    X.requires_grad_(True)\n",
    "    R_vals = R(X, M, model).detach().abs().cpu().numpy().flatten()  # .detach() spezza il grafo\n",
    "\n",
    "    idx = np.argsort(R_vals)[-N_sel:]\n",
    "    x_int = X.detach()[idx]  \n",
    "    mu_int = M.detach()[idx]\n",
    "\n",
    "    # Point on the border\n",
    "    x0 = torch.rand(N_boundary, 1, device=device)\n",
    "    zeros = torch.zeros_like(x0)\n",
    "    ones = torch.ones_like(x0)\n",
    "    xb = torch.cat([\n",
    "        torch.cat([x0, zeros], 1),\n",
    "        torch.cat([x0, ones], 1),\n",
    "        torch.cat([zeros, x0], 1),\n",
    "        torch.cat([ones, x0], 1)\n",
    "    ], 0)\n",
    "    mu_b = (torch.rand(1, 2, device=device) * 0.9 + 0.1).expand(xb.shape[0], -1)\n",
    "\n",
    "    return x_int, mu_int, xb, mu_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36482014-b43c-48c3-acad-c3ce0e950729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x: [N, 2], mu: [N, 2]\n",
    "def R(x, mu, net):\n",
    "    x.requires_grad_(True)\n",
    "    mu.requires_grad_(False)\n",
    "\n",
    "    u = net(x, mu)  # output shape: [N, 1]\n",
    "\n",
    "    # Compute the gradient ∇u (i.e. du/dx e du/dy)\n",
    "    grads = torch.autograd.grad(u.sum(), x, create_graph=True)[0]  # shape [N, 2]\n",
    "    u_x = grads[:, 0].unsqueeze(1)  # du/dx\n",
    "    u_y = grads[:, 1].unsqueeze(1)  # du/dy\n",
    "\n",
    "    # Laplacian = d²u/dx² + d²u/dy²\n",
    "    u_xx = torch.autograd.grad(u_x.sum(), x, create_graph=True)[0][:, 0].unsqueeze(1)\n",
    "    u_yy = torch.autograd.grad(u_y.sum(), x, create_graph=True)[0][:, 1].unsqueeze(1)\n",
    "    laplacian_u = u_xx + u_yy\n",
    "\n",
    "    # Nonlinear term\n",
    "    mu0 = mu[:, 0].unsqueeze(1)\n",
    "    mu1 = mu[:, 1].unsqueeze(1)\n",
    "    nonlinear = (mu0 / mu1) * (torch.exp(mu1 * u) - 1)\n",
    "\n",
    "    # Forcing term g(x)\n",
    "    x0 = x[:, 0].unsqueeze(1)\n",
    "    x1 = x[:, 1].unsqueeze(1)\n",
    "    g = 100 * torch.sin(2 * torch.pi * x0) * torch.cos(2 * torch.pi * x1)\n",
    "\n",
    "    # Residuo della PDE\n",
    "    residual = -laplacian_u + nonlinear - g\n",
    "\n",
    "    return residual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c83e43-1b02-4d9a-b5c4-f2ac690cd72e",
   "metadata": {},
   "source": [
    "#### **Train** computed on Kaggle (see the result in a different folder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae14cb4-d9c2-4344-b381-22765f9888d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_plot(model, epochs=50000, lr=1e-3, lambda_bc=1.0, patience=7500, delta=1e-4, batch_size=None, save_path=\"./models\"):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    model.to(device)\n",
    "    mse_loss = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_phys_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    best_model_path = None\n",
    "    epochs_no_improve = 0\n",
    "    using_lbfgs = False\n",
    "\n",
    "    loss_history_total = []\n",
    "    loss_history_phys = []\n",
    "    loss_history_bc = []\n",
    "    times_per_epoch = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        x_in, mu_in, xb, mu_b = generate_data()\n",
    "\n",
    "        if epoch != 0:\n",
    "            x_in, mu_in, xb, mu_b = adaptive_sample(model)\n",
    "\n",
    "        x_in = x_in.to(device)\n",
    "        mu_in = mu_in.to(device)\n",
    "        xb = xb.to(device)\n",
    "        mu_b = mu_b.to(device)\n",
    "\n",
    "        try:\n",
    "            if not using_lbfgs:\n",
    "                optimizer.zero_grad()\n",
    "                loss_phys = mse_loss(R(x_in, mu_in, model), torch.zeros_like(x_in[:, :1]))\n",
    "                u_b = model(xb, mu_b)\n",
    "                loss_bc = mse_loss(u_b, torch.zeros_like(u_b))\n",
    "\n",
    "                loss_total = loss_phys + lambda_bc * loss_bc\n",
    "\n",
    "                if torch.isnan(loss_total):\n",
    "                    raise ValueError(\"NaN detected in Adam loss computation\")\n",
    "\n",
    "                loss_total.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                if loss_phys.item() + delta < best_phys_loss:\n",
    "                    best_phys_loss = loss_phys.item()\n",
    "                    best_model_state = model.state_dict()\n",
    "                    best_model_path = os.path.join(save_path, f\"model_best.pth\")\n",
    "                    torch.save(best_model_state, best_model_path)\n",
    "                    torch.save(best_model_state, \"PINNResNet.pth\")\n",
    "                    epochs_no_improve = 0\n",
    "                else:\n",
    "                    epochs_no_improve += 1\n",
    "\n",
    "                # Interrompe l'allenamento se la total loss è < 1e-4\n",
    "                if loss_total.item() < 1e-4:\n",
    "                    final_model_path = os.path.join(save_path, \"model_total_loss_e-4_PINNResNet.pth\")\n",
    "                    torch.save(model.state_dict(), final_model_path)\n",
    "                    print(f\"\\n💾 Total loss reached e-4 at epoch {epoch}. Model saved at {final_model_path}\")\n",
    "                    break\n",
    "\n",
    "                if loss_bc.item() < 1e-1 and loss_phys.item() < 1e-1:\n",
    "                    print(f\"\\nSwitching to LBFGS at epoch {epoch}\")\n",
    "                    using_lbfgs = True\n",
    "                    optimizer = torch.optim.LBFGS(model.parameters(), lr=1.0, max_iter=500)\n",
    "                    if best_model_state:\n",
    "                        model.load_state_dict(best_model_state)\n",
    "\n",
    "            else:\n",
    "                def closure():\n",
    "                    optimizer.zero_grad()\n",
    "                    loss_phys_cl = mse_loss(R(x_in, mu_in, model), torch.zeros_like(x_in[:, :1]))\n",
    "                    u_b_cl = model(xb, mu_b)\n",
    "                    loss_bc_cl = mse_loss(u_b_cl, torch.zeros_like(u_b_cl))\n",
    "                    loss_total_cl = loss_phys_cl + lambda_bc * loss_bc_cl\n",
    "\n",
    "                    if torch.isnan(loss_total_cl):\n",
    "                        raise ValueError(\"NaN detected in LBFGS loss computation\")\n",
    "\n",
    "                    loss_total_cl.backward()\n",
    "                    return loss_total_cl\n",
    "\n",
    "                optimizer.step(closure)\n",
    "\n",
    "                loss_phys = mse_loss(R(x_in, mu_in, model), torch.zeros_like(x_in[:, :1]))\n",
    "                u_b = model(xb, mu_b)\n",
    "                loss_bc = mse_loss(u_b, torch.zeros_like(u_b))\n",
    "                loss_total = loss_phys + lambda_bc * loss_bc\n",
    "\n",
    "                # Interrompe l'allenamento se la total loss è < 1e-4\n",
    "                if loss_total.item() < 1e-3:\n",
    "                    final_model_path = os.path.join(save_path, \"model_total_loss_e-4_PINNResNet.pth\")\n",
    "                    torch.save(model.state_dict(), final_model_path)\n",
    "                    print(f\"\\n💾 Total loss reached e-4 at epoch {epoch}. Model saved at {final_model_path}\")\n",
    "                    break\n",
    "\n",
    "        except ValueError as e:\n",
    "            print(f\"\\n❌ Training stopped due to error at epoch {epoch}: {str(e)}\")\n",
    "            if best_model_state:\n",
    "                print(\"🔄 Reverting to best model state before NaN.\")\n",
    "                model.load_state_dict(best_model_state)\n",
    "                torch.save(best_model_state, \"PINNResNet.pth\")\n",
    "                nan_model_path = os.path.join(save_path, f\"model_nan_epoch{epoch}.pth\")\n",
    "                torch.save(model.state_dict(), nan_model_path)\n",
    "            break\n",
    "\n",
    "        loss_history_total.append(loss_total.item())\n",
    "        loss_history_phys.append(loss_phys.item())\n",
    "        loss_history_bc.append(loss_bc.item())\n",
    "        times_per_epoch.append(time.time() - start_time)\n",
    "\n",
    "        if epoch % 500 == 0 or epoch == epochs - 1:\n",
    "            opt_name = \"Adam\" if not using_lbfgs else \"LBFGS\"\n",
    "            print(f\"[{opt_name}] Epoch {epoch} - Total: {loss_total.item():.2e} | PDE: {loss_phys.item():.2e} | BC: {loss_bc.item():.2e}\")\n",
    "\n",
    "        if not using_lbfgs and epochs_no_improve >= patience:\n",
    "            print(f\"\\n🛑 Early stopping at epoch {epoch} | Best PDE loss: {best_phys_loss:.2e}\")\n",
    "            model.load_state_dict(best_model_state)\n",
    "            break\n",
    "\n",
    "    # Salva comunque il modello finale\n",
    "    final_model_path = os.path.join(save_path, \"model_final.pth\")\n",
    "    torch.save(model.state_dict(), final_model_path)\n",
    "\n",
    "    # Plotta le perdite\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(loss_history_total, label='Total Loss')\n",
    "    plt.plot(loss_history_phys, label='PDE Loss')\n",
    "    plt.plot(loss_history_bc, label='BC Loss')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Loss trends over training\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    total_epochs = len(loss_history_total)\n",
    "    avg_time = sum(times_per_epoch) / total_epochs\n",
    "    print(f\"\\n✅ Training complete: {total_epochs} epochs\")\n",
    "    print(f\"⏱ Average time per epoch: {avg_time:.4f} seconds\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf974512-0988-4c7a-af6a-5536c2852084",
   "metadata": {},
   "source": [
    "#### **Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e784ef-1d64-46ea-a3af-bd20941f57a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, epochs=10, lambda_bc=1.0):\n",
    "   \n",
    "    mse_loss = nn.MSELoss()\n",
    "    loss_bc = 1\n",
    "    loss_phys = 1 \n",
    "\n",
    "    for epoch in range(epochs):   \n",
    "             \n",
    "        x_in, mu_in, xb, mu_b = generate_data()\n",
    "        \n",
    "        model.eval()\n",
    "\n",
    "        # Phiycial Loss (residual PDE)\n",
    "        loss_phys = mse_loss(R(x_in, mu_in, model), torch.zeros_like(x_in[:, :1]))\n",
    "\n",
    "        # Boundary Loss (Dirichlet)\n",
    "        u_b = model(xb, mu_b)\n",
    "        loss_bc = mse_loss(u_b, torch.zeros_like(u_b))\n",
    "\n",
    "        # Total Loss \n",
    "        loss_total = loss_phys + lambda_bc * loss_bc\n",
    "\n",
    "        print(f\"Epoch {epoch} - Loss: {loss_total.item():.6e}  [PDE: {loss_phys.item():.2e}, BC: {loss_bc.item():.2e}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a583260-3dea-41fd-8341-515eba21d69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1- PINN40\n",
    "class PINN40(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.net = nn.Sequential(\n",
    "        nn.Linear(4, 40), nn.Tanh(),\n",
    "        nn.Linear(40, 40), nn.Tanh(),\n",
    "        nn.Linear(40, 40), nn.Tanh(),\n",
    "        nn.Linear(40, 40), nn.Tanh(),\n",
    "        nn.Linear(40, 1)\n",
    "    )\n",
    "  def forward(self, x, mu):\n",
    "    return self.net(torch.cat((x, mu), dim=1))\n",
    "\n",
    "PINN40 = PINN40()\n",
    "PINN40.load_state_dict(torch.load(\"./PINN40.pth\", map_location=\"cpu\"))\n",
    "validation(PINN40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0b88e6-a4bd-4c20-8d3e-37311a0cfd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2- PINN60 \n",
    "class PINN60(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.net = nn.Sequential(\n",
    "        nn.Linear(4, 60), nn.Tanh(),\n",
    "        nn.Linear(60, 60), nn.Tanh(),\n",
    "        nn.Linear(60, 60), nn.Tanh(),\n",
    "        nn.Linear(60, 60), nn.Tanh(),\n",
    "        nn.Linear(60, 1)\n",
    "    )\n",
    "  def forward(self, x, mu):\n",
    "    return self.net(torch.cat((x, mu), dim=1))\n",
    "\n",
    "PINN60 = PINN60()\n",
    "PINN60.load_state_dict(torch.load(\"./PINN60.pth\", map_location=\"cpu\"))\n",
    "validation(PINN60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3af50c8-8bfa-41c2-8cf6-d499d99e2fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3- PINN80\n",
    "class PINN80(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.net = nn.Sequential(\n",
    "        nn.Linear(4, 80), nn.Tanh(),\n",
    "        nn.Linear(80, 80), nn.Tanh(),\n",
    "        nn.Linear(80, 80), nn.Tanh(),\n",
    "        nn.Linear(80, 80), nn.Tanh(),\n",
    "        nn.Linear(80, 1)\n",
    "    )\n",
    "  def forward(self, x, mu):\n",
    "    return self.net(torch.cat((x, mu), dim=1))\n",
    "\n",
    "PINN80 = PINN80()\n",
    "PINN80.load_state_dict(torch.load(\"./PINN80.pth\", map_location=\"cpu\"))\n",
    "validation(PINN80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47211afc-4b66-4f7e-b72a-7adfedaff462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4- PINN128\n",
    "class PINN128(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.net = nn.Sequential(\n",
    "        nn.Linear(4, 128), nn.Tanh(),\n",
    "        nn.Linear(128, 128), nn.Tanh(),\n",
    "        nn.Linear(128, 128), nn.Tanh(),\n",
    "        nn.Linear(128, 128), nn.Tanh(),\n",
    "        nn.Linear(128, 1)\n",
    "    )\n",
    "  def forward(self, x, mu):\n",
    "    return self.net(torch.cat((x, mu), dim=1))\n",
    "\n",
    "PINN128 = PINN128()\n",
    "PINN128.load_state_dict(torch.load(\"./PINN128.pth\", map_location=\"cpu\"))\n",
    "validation(PINN128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b6bb3c-6518-4fe1-ac6b-5ef717fc2677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5- PINN_ReLU_60\n",
    "class PINN_ReLU_60(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(4, 60), nn.ReLU(),\n",
    "            nn.Linear(60, 60), nn.ReLU(),\n",
    "            nn.Linear(60, 60), nn.ReLU(),\n",
    "            nn.Linear(60, 60), nn.ReLU(),\n",
    "            nn.Linear(60, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mu):\n",
    "        return self.net(torch.cat((x, mu), dim=1))\n",
    "\n",
    "PINN_ReLU_60 = PINN_ReLU_60()\n",
    "PINN_ReLU_60.load_state_dict(torch.load(\"./PINN_ReLU_60.pth\", map_location=\"cpu\"))\n",
    "validation(PINN_ReLU_60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0e5f4d-d892-4d8e-b98e-d622453941ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6- PINNResNet\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(dim, dim), nn.Tanh(),\n",
    "            nn.Linear(dim, dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "class PINNResNet(nn.Module):\n",
    "    def __init__(self, hidden_dim=60, num_blocks=4):\n",
    "        super().__init__()\n",
    "        self.input = nn.Linear(4, hidden_dim)\n",
    "        self.blocks = nn.Sequential(*[ResBlock(hidden_dim) for _ in range(num_blocks)])\n",
    "        self.out = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x, mu):\n",
    "        z = torch.cat((x, mu), dim=1)\n",
    "        z = torch.tanh(self.input(z))\n",
    "        z = self.blocks(z)\n",
    "        return self.out(z)\n",
    "\n",
    "PINNResNet = PINNResNet()\n",
    "PINNResNet.load_state_dict(torch.load(\"./PINNResNet.pth\", map_location=\"cpu\"))\n",
    "validation(PINNResNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cd73bb-6619-4fa5-9497-7adc9dafb981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7- PINN_Tanh_Deep\n",
    "class PINN_Tanh_Deep(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        layers = [nn.Linear(4, 40), nn.Tanh()]\n",
    "        for _ in range(7):\n",
    "            layers += [nn.Linear(40, 40), nn.Tanh()]\n",
    "        layers.append(nn.Linear(40, 1))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, mu):\n",
    "        return self.net(torch.cat((x, mu), dim=1))\n",
    "\n",
    "PINN_Tanh_Deep = PINN_Tanh_Deep()\n",
    "PINN_Tanh_Deep.load_state_dict(torch.load(\"./PINN_Tanh_Deep.pth\", map_location=\"cpu\"))\n",
    "validation(PINN_Tanh_Deep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde0ce0e-1fb2-4e11-868e-ac46367e2719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8- PINN_SiLU_60 \n",
    "class PINN_SiLU_60(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(4, 60), nn.SiLU(),\n",
    "            nn.Linear(60, 60), nn.SiLU(),\n",
    "            nn.Linear(60, 60), nn.SiLU(),\n",
    "            nn.Linear(60, 60), nn.SiLU(),\n",
    "            nn.Linear(60, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mu):\n",
    "        return self.net(torch.cat((x, mu), dim=1))\n",
    "\n",
    "PINN_SiLU_60 = PINN_SiLU_60()\n",
    "PINN_SiLU_60.load_state_dict(torch.load(\"./PINN_SiLU_60.pth\", map_location=\"cpu\"))\n",
    "validation(PINN_SiLU_60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeb07c9-af56-4029-bd4f-bf0f841f8060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9- PINN_Sine_60 \n",
    "\n",
    "class Sine(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return torch.sin(input)\n",
    "\n",
    "class PINN_Sine_60(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(4, 60), Sine(),\n",
    "            nn.Linear(60, 60), Sine(),\n",
    "            nn.Linear(60, 60), Sine(),\n",
    "            nn.Linear(60, 60), Sine(),\n",
    "            nn.Linear(60, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mu):\n",
    "        return self.net(torch.cat((x, mu), dim=1))\n",
    "\n",
    "PINN_Sine_60 = PINN_Sine_60()\n",
    "PINN_Sine_60.load_state_dict(torch.load(\"./PINN_Sine_60.pth\", map_location=\"cpu\"))\n",
    "validation(PINN_Sine_60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21f693e-6862-43ff-a74c-358369d6d323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10- PINN_ELU_60 TODO\n",
    "class PINN_ELU_60(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(4, 60), nn.ELU(),\n",
    "            nn.Linear(60, 60), nn.ELU(),\n",
    "            nn.Linear(60, 60), nn.ELU(),\n",
    "            nn.Linear(60, 60), nn.ELU(),\n",
    "            nn.Linear(60, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mu):\n",
    "        return self.net(torch.cat((x, mu), dim=1))\n",
    "\n",
    "PINN_ELU_60 = PINN_ELU_60()\n",
    "PINN_ELU_60.load_state_dict(torch.load(\"./PINN_ELU_60.pth\", map_location=\"cpu\"))\n",
    "validation(PINN_ELU_60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b45e3f-e4e2-4df7-8975-4c7942890172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11- PINN_LN_60\n",
    "class PINN_LN_60(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(4, 60), nn.LayerNorm(60), nn.Tanh(),\n",
    "            nn.Linear(60, 60), nn.LayerNorm(60), nn.Tanh(),\n",
    "            nn.Linear(60, 60), nn.LayerNorm(60), nn.Tanh(),\n",
    "            nn.Linear(60, 60), nn.LayerNorm(60), nn.Tanh(),\n",
    "            nn.Linear(60, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mu):\n",
    "        return self.net(torch.cat((x, mu), dim=1))\n",
    "\n",
    "PINN_LN_60 = PINN_LN_60()\n",
    "PINN_LN_60.load_state_dict(torch.load(\"./PINN_LN_60.pth\", map_location=\"cpu\"))\n",
    "validation(PINN_LN_60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6187ba7b-6c75-4415-bcb0-8090384b7067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12- PINN_MixAct\n",
    "class PINN_MixAct(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(4, 60), nn.Tanh(),\n",
    "            nn.Linear(60, 60), nn.ReLU(),\n",
    "            nn.Linear(60, 60), nn.Tanh(),\n",
    "            nn.Linear(60, 60), nn.ReLU(),\n",
    "            nn.Linear(60, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mu):\n",
    "        return self.net(torch.cat((x, mu), dim=1))\n",
    "\n",
    "PINN_MixAct = PINN_MixAct()\n",
    "PINN_MixAct.load_state_dict(torch.load(\"./PINN_MixAct.pth\", map_location=\"cpu\"))\n",
    "validation(PINN_MixAct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384f6acd-67b0-49f8-ae7b-58ae79b90c9b",
   "metadata": {},
   "source": [
    "#### **Compute the error** on the quadrature points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d209d99b-366a-4071-8f03-63da35894bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute quadrature points\n",
    "quadrature_points = []\n",
    "file_path = \"./Export/SolutionOnPoints_0.inp\" # Take the quadrature poing just computed in the HIGH FIDELITY part (before POD)\n",
    "\n",
    "with open(file_path, \"r\") as f:\n",
    "    next(f)  # No point in the header (first line) of the file\n",
    "    for line in f:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) < 4:\n",
    "            continue\n",
    "        try:\n",
    "            idx = int(parts[0])\n",
    "            x = float(parts[1])\n",
    "            y = float(parts[2])\n",
    "        except ValueError:\n",
    "            # Righe non dati, le salto\n",
    "            continue\n",
    "\n",
    "        quadrature_points.append((x, y))\n",
    "quadrature_points = np.array(quadrature_points)  # shape (N,2)\n",
    "print(f\"quadrature_points.shape: {quadrature_points.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fddb46-d8f7-4ec9-92c3-5d2e48d0129c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_mu_0 = sample_mu_0.reshape(-1, 1)  # shape: (300, 1)\n",
    "sample_mu_1 = sample_mu_1.reshape(-1, 1)  # shape: (300, 1)\n",
    "\n",
    "# Now concatenate column-wise\n",
    "test_set = np.hstack((sample_mu_0, sample_mu_1))\n",
    "\n",
    "print(f\"test_set.shape: {test_set.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2a744a-f16e-4938-9771-3231fa04ba40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv_file(name_model):\n",
    "    coords_tensor = torch.tensor(quadrature_points, dtype=torch.float32)  # (N, 2) # (1470, 2)\n",
    "    \n",
    "    all_preds = []\n",
    "    all_u_x = []\n",
    "    all_u_y = []\n",
    "    times_pinn = []\n",
    "    \n",
    "    for mu in test_set: # (300,2)\n",
    "        mu0_val, mu1_val = mu\n",
    "    \n",
    "        # Separate mu and x to give to the net \n",
    "        x_tensor = coords_tensor  # (N, 2)\n",
    "        mu_tensor = torch.full((coords_tensor.shape[0], 2), fill_value=0.0, dtype=torch.float32)\n",
    "        mu_tensor[:, 0] = mu0_val\n",
    "        mu_tensor[:, 1] = mu1_val\n",
    "    \n",
    "        x_tensor.requires_grad_(True)\n",
    "    \n",
    "        start_time = time.time()\n",
    "        u = net(x_tensor, mu_tensor)  # (N, 1)\n",
    "        time_pinn = time.time() - start_time\n",
    "        times_pinn.append(time_pinn)\n",
    "    \n",
    "        u_pred = u.detach().cpu().numpy().flatten()\n",
    "        all_preds.append(u_pred)\n",
    "    \n",
    "        grads = torch.autograd.grad(\n",
    "            outputs=u.sum(), inputs=x_tensor, create_graph=False, retain_graph=False\n",
    "        )[0]  # (N, 2)\n",
    "        u_x = grads[:, 0].detach().cpu().numpy()\n",
    "        u_y = grads[:, 1].detach().cpu().numpy()\n",
    "    \n",
    "        all_u_x.append(u_x)\n",
    "        all_u_y.append(u_y)\n",
    "    \n",
    "    all_preds = np.array(all_preds).T      # (N_punti, N_mu )\n",
    "    all_u_x = np.array(all_u_x).T          # (N_punti, N_mu )\n",
    "    all_u_y = np.array(all_u_y).T          # (N_punti, N_mu )\n",
    "    \n",
    "    col_names = [f\"mu0_{mu[0]:.3f}_mu1_{mu[1]:.3f}\" for mu in test_set]\n",
    "    \n",
    "    # Save u\n",
    "    df_u = pd.DataFrame(all_preds, columns=col_names)\n",
    "    df_u.to_csv(f\"pred_u_{name_model}.csv\", index=False)\n",
    "    \n",
    "    # Save u_x\n",
    "    df_ux = pd.DataFrame(all_u_x, columns=col_names)\n",
    "    df_ux.to_csv(f\"pred_u_x_{name_model}.csv\", index=False) \n",
    "    \n",
    "    # Save u_y\n",
    "    df_uy = pd.DataFrame(all_u_y, columns=col_names)\n",
    "    df_uy.to_csv(f\"pred_u_y_{name_model}.csv\", index=False)\n",
    "    \n",
    "    # Save tempi\n",
    "    df_times = pd.DataFrame(times_pinn)\n",
    "    df_times.to_csv(f\"time_pinn_{name_model}.csv\", index=False)\n",
    "    \n",
    "    print(\"Save: u, u_x, u_y, time\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad6762c-c938-4d21-9872-c6bb275adf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv(name_model):\n",
    "    # Carica il CSV delle predizioni pred_u, pred_u_x, pred_u_y, time_pinn\n",
    "    df = pd.read_csv(f\"pred_u_{name_model}.csv\")\n",
    "    \n",
    "    # Estrai i valori come array NumPy: shape (N_punti, N_mu)\n",
    "    sol_quad_pinn = df.values.T\n",
    "    print(np.array(sol_quad_pinn).shape)\n",
    "    \n",
    "    print(f\"Caricate predizioni: shape = {sol_quad_pinn.shape}\")\n",
    "    \n",
    "    # Carica il CSV della derivata rispetto a x\n",
    "    df = pd.read_csv(f\"pred_u_x_{name_model}.csv\")\n",
    "    \n",
    "    # Estrai i valori come array NumPy: shape (N_punti, N_mu)\n",
    "    der_x_quad_pinn = df.values.T\n",
    "    print(np.array(der_x_quad_pinn).shape)\n",
    "    \n",
    "    # Carica il CSV della derivata rispetto a y\n",
    "    df = pd.read_csv(f\"pred_u_y_{name_model}.csv\")\n",
    "    \n",
    "    # Estrai i valori come array NumPy: shape (N_punti, N_mu)\n",
    "    der_y_quad_pinn = df.values.T\n",
    "    print(np.array(der_y_quad_pinn).shape)\n",
    "    \n",
    "    # Carica il CSV dei tempi\n",
    "    df = pd.read_csv(f\"time_pinn_{name_model}.csv\")\n",
    "    return sol_quad_pinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4109cdeb-16b0-4e8f-94f6-dc9567bd1988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_L2_H1_errors_separated(HF_u_set, HF_ux_set, HF_uy_set, POD_u_set, POD_ux_set, POD_uy_set, weights=None):\n",
    "    l2_errors = []\n",
    "    l2_rel_errors = []\n",
    "\n",
    "    for u_HF, u_POD in zip(HF_u_set,POD_u_set):\n",
    "\n",
    "        # Compute errors\n",
    "        err_u = u_POD - u_HF\n",
    "\n",
    "        if weights is not None:\n",
    "            l2 = np.sqrt(np.sum(weights * err_u**2))\n",
    "            \n",
    "            l2_rel = l2/np.sqrt(np.sum(weights * u_HF**2))\n",
    "            \n",
    "        else:\n",
    "            l2 = np.linalg.norm(err_u)\n",
    "           \n",
    "\n",
    "        l2_errors.append(l2)\n",
    "       \n",
    "        l2_rel_errors.append(l2_rel)\n",
    "        \n",
    "    avg_l2 = np.mean(l2_errors)\n",
    "   \n",
    "    avg_l2_rel = np.mean(l2_rel_errors)\n",
    "    \n",
    "    print(f\"Error L^2 (abs) computed on quadrature points: {avg_l2:.4e}\")\n",
    "    print(f\"Error L^2 (rel) computed on quadrature points: {avg_l2_rel:.4e}\")\n",
    "    \n",
    "    return {\n",
    "        \"Error L^2 (abs) computed on quadrature points\": avg_l2,\n",
    "        \"Error L^2 (rel) computed on quadrature points\": avg_l2_rel,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489ccd47-046d-45a5-8daa-d7d29dcd9ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1- PINN40\n",
    "class PINN40(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.net = nn.Sequential(\n",
    "        nn.Linear(4, 40), nn.Tanh(),\n",
    "        nn.Linear(40, 40), nn.Tanh(),\n",
    "        nn.Linear(40, 40), nn.Tanh(),\n",
    "        nn.Linear(40, 40), nn.Tanh(),\n",
    "        nn.Linear(40, 1)\n",
    "    )\n",
    "  def forward(self, x, mu):\n",
    "    return self.net(torch.cat((x, mu), dim=1))\n",
    "\n",
    "\n",
    "# Caricamento del modello\n",
    "net = PINN40()\n",
    "net.load_state_dict(torch.load(\"PINN40.pth\", map_location=\"cpu\")) # Load the net\n",
    "net.eval() # Put the net in eval mode\n",
    "\n",
    "name_model = \"PINN40\"\n",
    "\n",
    "save_csv_file(name_model)\n",
    "\n",
    "sol_quad_pinn = csv(name_model)\n",
    "\n",
    "der_x_quad_hf = 0\n",
    "der_y_quad_hf = 0\n",
    "der_x_quad_pinn = 0\n",
    "der_y_quad_pinn = 0\n",
    "\n",
    "errors_u_set = compute_L2_H1_errors_separated(sol_quad_hf,der_x_quad_hf,der_y_quad_hf, sol_quad_pinn,der_x_quad_pinn,der_y_quad_pinn, weights=quadratureWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4023bc5-2ade-4840-b196-dba2434ad981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2- PINN60\n",
    "class PINN60(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.net = nn.Sequential(\n",
    "        nn.Linear(4, 60), nn.Tanh(),\n",
    "        nn.Linear(60, 60), nn.Tanh(),\n",
    "        nn.Linear(60, 60), nn.Tanh(),\n",
    "        nn.Linear(60, 60), nn.Tanh(),\n",
    "        nn.Linear(60, 1)\n",
    "    )\n",
    "  def forward(self, x, mu):\n",
    "    return self.net(torch.cat((x, mu), dim=1))\n",
    "\n",
    "net = PINN60()\n",
    "net.load_state_dict(torch.load(\"PINN60.pth\", map_location=\"cpu\")) # CHANGE HERE THE NAME\n",
    "\n",
    "net.eval() # Put the net in eval mode\n",
    "\n",
    "name_model = \"PINN60\"\n",
    "save_csv_file(name_model)\n",
    "\n",
    "sol_quad_pinn = csv(name_model)\n",
    "\n",
    "der_x_quad_hf = 0\n",
    "der_y_quad_hf = 0\n",
    "errors_u_set = compute_L2_H1_errors_separated(sol_quad_hf,der_x_quad_hf,der_y_quad_hf, sol_quad_pinn,der_x_quad_pinn,der_y_quad_pinn, weights=quadratureWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ebab89-ebd4-4e02-a8db-7b96ba6d88c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3- PINN80\n",
    "class PINN80(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.net = nn.Sequential(\n",
    "        nn.Linear(4, 80), nn.Tanh(),\n",
    "        nn.Linear(80, 80), nn.Tanh(),\n",
    "        nn.Linear(80, 80), nn.Tanh(),\n",
    "        nn.Linear(80, 80), nn.Tanh(),\n",
    "        nn.Linear(80, 1)\n",
    "    )\n",
    "  def forward(self, x, mu):\n",
    "    return self.net(torch.cat((x, mu), dim=1))\n",
    "\n",
    "# Caricamento del modello\n",
    "net = PINN80()\n",
    "net.load_state_dict(torch.load(\"PINN80.pth\", map_location=\"cpu\")) # Load the net\n",
    "\n",
    "net.eval() # Put the net in eval mode\n",
    "\n",
    "name_model = \"PINN80\"\n",
    "\n",
    "save_csv_file(name_model)\n",
    "\n",
    "sol_quad_pinn = csv(name_model)\n",
    "\n",
    "der_x_quad_hf = 0\n",
    "der_y_quad_hf = 0\n",
    "errors_u_set = compute_L2_H1_errors_separated(sol_quad_hf,der_x_quad_hf,der_y_quad_hf, sol_quad_pinn,der_x_quad_pinn,der_y_quad_pinn, weights=quadratureWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abf329d-c86d-4a29-80e2-87c38d1c9573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4- PINN128\n",
    "class PINN128(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.net = nn.Sequential(\n",
    "        nn.Linear(4, 128), nn.Tanh(),\n",
    "        nn.Linear(128, 128), nn.Tanh(),\n",
    "        nn.Linear(128, 128), nn.Tanh(),\n",
    "        nn.Linear(128, 128), nn.Tanh(),\n",
    "        nn.Linear(128, 1)\n",
    "    )\n",
    "  def forward(self, x, mu):\n",
    "    return self.net(torch.cat((x, mu), dim=1))\n",
    "\n",
    "net = PINN128()\n",
    "net.load_state_dict(torch.load(\"PINN128.pth\", map_location=\"cpu\")) # CHANGE HERE THE NAME\n",
    "\n",
    "net.eval() # Put the net in eval mode\n",
    "\n",
    "model_name = \"PINN128\"\n",
    "save_csv_file(model_name)\n",
    "\n",
    "sol_quad_pinn = csv(model_name)\n",
    "\n",
    "der_x_quad_hf = 0\n",
    "der_y_quad_hf = 0\n",
    "errors_u_set = compute_L2_H1_errors_separated(sol_quad_hf,der_x_quad_hf,der_y_quad_hf, sol_quad_pinn,der_x_quad_pinn,der_y_quad_pinn, weights=quadratureWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1b00a7-c6d3-4ec5-9d4a-c090684ddbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5- PINN_ReLU_60 \n",
    "class PINN_ReLU_60(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(4, 60), nn.ReLU(),\n",
    "            nn.Linear(60, 60), nn.ReLU(),\n",
    "            nn.Linear(60, 60), nn.ReLU(),\n",
    "            nn.Linear(60, 60), nn.ReLU(),\n",
    "            nn.Linear(60, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mu):\n",
    "        return self.net(torch.cat((x, mu), dim=1))\n",
    "\n",
    "net = PINN_ReLU_60()\n",
    "net.load_state_dict(torch.load(\"PINN_ReLU_60.pth\", map_location=\"cpu\")) # CHANGE HERE THE NAME\n",
    "\n",
    "net.eval() # Put the net in eval mode\n",
    "\n",
    "name_model = \"PINN_ReLU_60.pth\"\n",
    "save_csv_file(name_model)\n",
    "sol_quad_pinn = csv(name_model)\n",
    "\n",
    "der_x_quad_hf = 0\n",
    "der_y_quad_hf = 0\n",
    "errors_u_set = compute_L2_H1_errors_separated(sol_quad_hf,der_x_quad_hf,der_y_quad_hf, sol_quad_pinn,der_x_quad_pinn,der_y_quad_pinn, weights=quadratureWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ac5501-c898-4283-86ad-cf5d9247b038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6- PINNResNet\n",
    "class PINNResNet(nn.Module):\n",
    "    def __init__(self, hidden_dim=60, num_blocks=4):\n",
    "        super().__init__()\n",
    "        self.input = nn.Linear(4, hidden_dim)\n",
    "        self.blocks = nn.Sequential(*[ResBlock(hidden_dim) for _ in range(num_blocks)])\n",
    "        self.out = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x, mu):\n",
    "        z = torch.cat((x, mu), dim=1)\n",
    "        z = torch.tanh(self.input(z))\n",
    "        z = self.blocks(z)\n",
    "        return self.out(z)\n",
    "\n",
    "net = PINNResNet()\n",
    "net.load_state_dict(torch.load(\"PINNResNet.pth\", map_location=\"cpu\")) # CHANGE HERE THE NAME\n",
    "\n",
    "net.eval() # Put the net in eval mode\n",
    "\n",
    "name_model = \"PINNResNet.pth\"\n",
    "\n",
    "save_csv_file(name_model)\n",
    "\n",
    "sol_quad_pinn = csv(name_model)\n",
    "\n",
    "der_x_quad_hf = 0\n",
    "der_y_quad_hf = 0\n",
    "errors_u_set = compute_L2_H1_errors_separated(sol_quad_hf,der_x_quad_hf,der_y_quad_hf, sol_quad_pinn,der_x_quad_pinn,der_y_quad_pinn, weights=quadratureWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3a5e0c-387f-4fce-ac21-0526f0437042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7- PINN_Tanh_Deep\n",
    "class PINN_Tanh_Deep(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        layers = [nn.Linear(4, 40), nn.Tanh()]\n",
    "        for _ in range(7):\n",
    "            layers += [nn.Linear(40, 40), nn.Tanh()]\n",
    "        layers.append(nn.Linear(40, 1))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, mu):\n",
    "        return self.net(torch.cat((x, mu), dim=1))\n",
    "\n",
    "net = PINN_Tanh_Deep()\n",
    "net.load_state_dict(torch.load(\"PINN_Tanh_Deep.pth\", map_location=\"cpu\")) # CHANGE HERE THE NAME\n",
    "\n",
    "net.eval() # Put the net in eval mode\n",
    "\n",
    "name_model = \"PINN_Tanh_Deep\"\n",
    "\n",
    "save_csv_file(name_model)\n",
    "\n",
    "sol_quad_pinn = csv(name_model)\n",
    "\n",
    "der_x_quad_hf = 0\n",
    "der_y_quad_hf = 0\n",
    "errors_u_set = compute_L2_H1_errors_separated(sol_quad_hf,der_x_quad_hf,der_y_quad_hf, sol_quad_pinn,der_x_quad_pinn,der_y_quad_pinn, weights=quadratureWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda84a1b-4a13-46f2-8506-f9f6ba0cde42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8- PINN_SiLU_60\n",
    "class PINN_SiLU_60(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(4, 60), nn.SiLU(),\n",
    "            nn.Linear(60, 60), nn.SiLU(),\n",
    "            nn.Linear(60, 60), nn.SiLU(),\n",
    "            nn.Linear(60, 60), nn.SiLU(),\n",
    "            nn.Linear(60, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mu):\n",
    "        return self.net(torch.cat((x, mu), dim=1))\n",
    "\n",
    "net = PINN_SiLU_60()\n",
    "net.load_state_dict(torch.load(\"PINN_SiLU_60.pth\", map_location=\"cpu\")) # CHANGE HERE THE NAME\n",
    "\n",
    "name_model = \"PINN_SiLU_60.pth\"\n",
    "net.eval() # Put the net in eval mode\n",
    "\n",
    "save_csv_file(name_model)\n",
    "\n",
    "sol_quad_pinn = csv(name_model)\n",
    "\n",
    "der_x_quad_hf = 0\n",
    "der_y_quad_hf = 0\n",
    "errors_u_set = compute_L2_H1_errors_separated(sol_quad_hf,der_x_quad_hf,der_y_quad_hf, sol_quad_pinn,der_x_quad_pinn,der_y_quad_pinn, weights=quadratureWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd51180-1fdf-4d3d-8647-dd5634c80e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9- PINN_Sine_60 TODO\n",
    "class PINN_Sine_60(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(4, 60), Sine(),\n",
    "            nn.Linear(60, 60), Sine(),\n",
    "            nn.Linear(60, 60), Sine(),\n",
    "            nn.Linear(60, 60), Sine(),\n",
    "            nn.Linear(60, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mu):\n",
    "        return self.net(torch.cat((x, mu), dim=1))\n",
    "\n",
    "net = PINN_Sine_60()\n",
    "net.load_state_dict(torch.load(\"PINN_Sine_60.pth\", map_location=\"cpu\")) # CHANGE HERE THE NAME\n",
    "\n",
    "net.eval() # Put the net in eval mode\n",
    "\n",
    "name_model = \"PINN_Sine_60\"\n",
    "save_csv_file(name_model)\n",
    "\n",
    "sol_quad_pinn = csv(name_model)\n",
    "\n",
    "der_x_quad_hf = 0\n",
    "der_y_quad_hf = 0\n",
    "errors_u_set = compute_L2_H1_errors_separated(sol_quad_hf,der_x_quad_hf,der_y_quad_hf, sol_quad_pinn,der_x_quad_pinn,der_y_quad_pinn, weights=quadratureWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2ebc22-aa7e-4a16-affd-71401df08867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10- PINN_ELU_60\n",
    "class PINN_ELU_60(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(4, 60), nn.ELU(),\n",
    "            nn.Linear(60, 60), nn.ELU(),\n",
    "            nn.Linear(60, 60), nn.ELU(),\n",
    "            nn.Linear(60, 60), nn.ELU(),\n",
    "            nn.Linear(60, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mu):\n",
    "        return self.net(torch.cat((x, mu), dim=1))\n",
    "\n",
    "net = PINN_ELU_60()\n",
    "net.load_state_dict(torch.load(\"PINN_ELU_60.pth\", map_location=\"cpu\")) # CHANGE HERE THE NAME\n",
    "\n",
    "net.eval() # Put the net in eval mode\n",
    "\n",
    "name_model = \"PINN_ELU_60\"\n",
    "save_csv_file(name_model)\n",
    "\n",
    "sol_quad_pinn = csv(name_model)\n",
    "\n",
    "der_x_quad_hf = 0\n",
    "der_y_quad_hf = 0\n",
    "errors_u_set = compute_L2_H1_errors_separated(sol_quad_hf,der_x_quad_hf,der_y_quad_hf, sol_quad_pinn,der_x_quad_pinn,der_y_quad_pinn, weights=quadratureWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973e103f-1ba6-48b1-8643-b1554533d795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11- PINN_LN_60\n",
    "class PINN_LN_60(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(4, 60), nn.LayerNorm(60), nn.Tanh(),\n",
    "            nn.Linear(60, 60), nn.LayerNorm(60), nn.Tanh(),\n",
    "            nn.Linear(60, 60), nn.LayerNorm(60), nn.Tanh(),\n",
    "            nn.Linear(60, 60), nn.LayerNorm(60), nn.Tanh(),\n",
    "            nn.Linear(60, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mu):\n",
    "        return self.net(torch.cat((x, mu), dim=1))\n",
    "\n",
    "net = PINN_LN_60()\n",
    "net.load_state_dict(torch.load(\"PINN_LN_60.pth\", map_location=\"cpu\")) # CHANGE HERE THE NAME\n",
    "\n",
    "net.eval() # Put the net in eval mode\n",
    "\n",
    "model_name = \"PINN_LN_60\"\n",
    "save_csv_file(model_name)\n",
    "sol_quad_pinn = csv(model_name)\n",
    "\n",
    "der_x_quad_hf = 0\n",
    "der_y_quad_hf = 0\n",
    "errors_u_set = compute_L2_H1_errors_separated(sol_quad_hf,der_x_quad_hf,der_y_quad_hf, sol_quad_pinn,der_x_quad_pinn,der_y_quad_pinn, weights=quadratureWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a1a411-d0d9-46ce-9b41-e032cccb9db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12- PINN_MixAct\n",
    "class PINN_MixAct(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(4, 60), nn.Tanh(),\n",
    "            nn.Linear(60, 60), nn.ReLU(),\n",
    "            nn.Linear(60, 60), nn.Tanh(),\n",
    "            nn.Linear(60, 60), nn.ReLU(),\n",
    "            nn.Linear(60, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mu):\n",
    "        return self.net(torch.cat((x, mu), dim=1))\n",
    "\n",
    "net = PINN_MixAct()\n",
    "net.load_state_dict(torch.load(\"PINN_MixAct.pth\", map_location=\"cpu\")) # CHANGE HERE THE NAME\n",
    "\n",
    "net.eval() # Put the net in eval mode\n",
    "\n",
    "model_name = \"PINN_MixAct\"\n",
    "save_csv_file(model_name)\n",
    "\n",
    "sol_quad_pinn = csv(model_name)\n",
    "\n",
    "der_x_quad_hf = 0\n",
    "der_y_quad_hf = 0\n",
    "errors_u_set = compute_L2_H1_errors_separated(sol_quad_hf,der_x_quad_hf,der_y_quad_hf, sol_quad_pinn,der_x_quad_pinn,der_y_quad_pinn, weights=quadratureWeights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
